{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy\nimport nltk\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom pymystem3 import Mystem\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:54:00.212115Z","iopub.execute_input":"2023-06-25T22:54:00.213176Z","iopub.status.idle":"2023-06-25T22:54:00.220201Z","shell.execute_reply.started":"2023-06-25T22:54:00.213138Z","shell.execute_reply":"2023-06-25T22:54:00.218646Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:33:55.008034Z","iopub.execute_input":"2023-06-25T20:33:55.008385Z","iopub.status.idle":"2023-06-25T20:33:55.061349Z","shell.execute_reply.started":"2023-06-25T20:33:55.008357Z","shell.execute_reply":"2023-06-25T20:33:55.060275Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pymystem3","metadata":{"execution":{"iopub.status.busy":"2023-06-25T21:30:22.496823Z","iopub.execute_input":"2023-06-25T21:30:22.497210Z","iopub.status.idle":"2023-06-25T21:30:36.109678Z","shell.execute_reply.started":"2023-06-25T21:30:22.497180Z","shell.execute_reply":"2023-06-25T21:30:36.108521Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Collecting pymystem3\n  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pymystem3) (2.28.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (2023.5.7)\nInstalling collected packages: pymystem3\nSuccessfully installed pymystem3-0.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/russian-language-toxic-comments/labeled.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T23:35:47.295148Z","iopub.execute_input":"2023-06-25T23:35:47.295820Z","iopub.status.idle":"2023-06-25T23:35:47.397768Z","shell.execute_reply.started":"2023-06-25T23:35:47.295790Z","shell.execute_reply":"2023-06-25T23:35:47.396896Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"                                             comment  toxic\n0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n2                          Собаке - собачья смерть\\n    1.0\n3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Собаке - собачья смерть\\n</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['toxic'] = data['toxic'].astype(int)\ndata = data.replace('\\n',' ', regex=True)\ndata = data.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\ndata['comment'] = data['comment'].str.lower()\ndata = data.replace('[^а-яА-я]', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T23:35:49.285715Z","iopub.execute_input":"2023-06-25T23:35:49.286175Z","iopub.status.idle":"2023-06-25T23:35:50.147758Z","shell.execute_reply.started":"2023-06-25T23:35:49.286129Z","shell.execute_reply":"2023-06-25T23:35:50.146624Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T23:35:51.871578Z","iopub.execute_input":"2023-06-25T23:35:51.871947Z","iopub.status.idle":"2023-06-25T23:35:51.882226Z","shell.execute_reply.started":"2023-06-25T23:35:51.871918Z","shell.execute_reply":"2023-06-25T23:35:51.881163Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"                                             comment  toxic\n0                верблюдов то за что  дебилы  бл          1\n1  хохлы  это отдушина затюканого россиянина  мол...      1\n2                           собаке   собачья смерть       1\n3  страницу обнови  дебил  это тоже не оскорблени...      1\n4  тебя не убедил   страничный пдф в том  что скр...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>верблюдов то за что  дебилы  бл</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>хохлы  это отдушина затюканого россиянина  мол...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>собаке   собачья смерть</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>страницу обнови  дебил  это тоже не оскорблени...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>тебя не убедил   страничный пдф в том  что скр...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mystem = Mystem()\n\ndef lemmat(comment):\n    word_list = word_tokenize(comment)\n    lemmas = [mystem.lemmatize(w)[0] for w in word_list if not w.lower() in stop_list]\n    return lemmas\n\nfor i in tqdm(range(len(data))):\n    data['comment'][i] = lemmat(data[\"comment\"][i])","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:54:39.787748Z","iopub.execute_input":"2023-06-25T22:54:39.788132Z","iopub.status.idle":"2023-06-25T22:55:34.119151Z","shell.execute_reply.started":"2023-06-25T22:54:39.788099Z","shell.execute_reply":"2023-06-25T22:55:34.116321Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stderr","text":"  0%|          | 0/14412 [00:00<?, ?it/s]/tmp/ipykernel_27/4109446096.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data['comment'][i] = lemmat(data[\"comment\"][i])\n100%|██████████| 14412/14412 [00:54<00:00, 265.34it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"data['comment'] = data['comment'].apply(lambda x: ', '.join(x))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:55:34.121613Z","iopub.execute_input":"2023-06-25T22:55:34.122344Z","iopub.status.idle":"2023-06-25T22:55:34.176866Z","shell.execute_reply.started":"2023-06-25T22:55:34.122301Z","shell.execute_reply":"2023-06-25T22:55:34.175684Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\ndata['tokenized_comment'] = data['comment'].apply(nltk.word_tokenize)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:55:34.182227Z","iopub.execute_input":"2023-06-25T22:55:34.185435Z","iopub.status.idle":"2023-06-25T22:55:41.322417Z","shell.execute_reply.started":"2023-06-25T22:55:34.185387Z","shell.execute_reply":"2023-06-25T22:55:41.321333Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"                                             comment  toxic  \\\n0                    верблюд, ?, дебил, ,\\n, бл, ...      1   \n1  хохол, ,\\n, это, отдушина, затюканый, россияни...      1   \n2                       собака, -\\n, собачий, смерть      1   \n3  страница, обновлять, ,\\n, дебил, ., это, оскор...      1   \n4  убеждать, 6, пдф, ,\\n, скрипалый, отравлять, р...      1   \n\n                                   tokenized_comment  \n0     [верблюд, ,, ?, ,, дебил, ,, ,, ,, бл, ,, ...]  \n1  [хохол, ,, ,, ,, это, ,, отдушина, ,, затюканы...  \n2              [собака, ,, -, ,, собачий, ,, смерть]  \n3  [страница, ,, обновлять, ,, ,, ,, дебил, ,, .,...  \n4  [убеждать, ,, 6, ,, пдф, ,, ,, ,, скрипалый, ,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>toxic</th>\n      <th>tokenized_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>верблюд, ?, дебил, ,\\n, бл, ...</td>\n      <td>1</td>\n      <td>[верблюд, ,, ?, ,, дебил, ,, ,, ,, бл, ,, ...]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>хохол, ,\\n, это, отдушина, затюканый, россияни...</td>\n      <td>1</td>\n      <td>[хохол, ,, ,, ,, это, ,, отдушина, ,, затюканы...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>собака, -\\n, собачий, смерть</td>\n      <td>1</td>\n      <td>[собака, ,, -, ,, собачий, ,, смерть]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>страница, обновлять, ,\\n, дебил, ., это, оскор...</td>\n      <td>1</td>\n      <td>[страница, ,, обновлять, ,, ,, ,, дебил, ,, .,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>убеждать, 6, пдф, ,\\n, скрипалый, отравлять, р...</td>\n      <td>1</td>\n      <td>[убеждать, ,, 6, ,, пдф, ,, ,, ,, скрипалый, ,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_comments = data['tokenized_comment'].apply(lambda x: ' '.join(x))\ntfidf_vectors = vectorizer.fit_transform(tokenized_comments)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:55:41.324573Z","iopub.execute_input":"2023-06-25T22:55:41.325844Z","iopub.status.idle":"2023-06-25T22:55:41.889523Z","shell.execute_reply.started":"2023-06-25T22:55:41.325804Z","shell.execute_reply":"2023-06-25T22:55:41.888306Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"X = tfidf_vectors\ny = data['toxic']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:55:51.672947Z","iopub.execute_input":"2023-06-25T22:55:51.673384Z","iopub.status.idle":"2023-06-25T22:55:51.689453Z","shell.execute_reply.started":"2023-06-25T22:55:51.673350Z","shell.execute_reply":"2023-06-25T22:55:51.688465Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"N = 14412\nl2_coef = 0.5\nalpha = 2\nbeta = 2\nbatch_size = int(N/20)\n\nclf = LogisticRegression(C=1/(2*l2_coef), solver='sag')\nclf.fit(X_train, y_train)\n\ny_pred_val = clf.predict(X_val)\ny_pred_test = clf.predict(X_test)\n\nthreshold = 0.5\n\nprint(\"val acc:\", balanced_accuracy_score(y_val, y_pred_val))\nprint(\"test acc:\", balanced_accuracy_score(y_test, y_pred_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T22:55:53.578842Z","iopub.execute_input":"2023-06-25T22:55:53.579191Z","iopub.status.idle":"2023-06-25T22:55:53.685686Z","shell.execute_reply.started":"2023-06-25T22:55:53.579162Z","shell.execute_reply":"2023-06-25T22:55:53.684554Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"val acc: 0.779036482404578\ntest acc: 0.7861553202119407\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Все слова с весами:","metadata":{}},{"cell_type":"code","source":"weights = clf.coef_[0]\nword_weights = {word: weights[i] for word, i in vectorizer.vocabulary_.items()}\nword_weight_pairs = [(word, weight) for word, weight in word_weights.items()]\ndf = pd.DataFrame(word_weight_pairs, columns=['word', 'weight'])\nprint(df.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T23:34:57.530372Z","iopub.execute_input":"2023-06-25T23:34:57.531094Z","iopub.status.idle":"2023-06-25T23:34:57.583360Z","shell.execute_reply.started":"2023-06-25T23:34:57.531061Z","shell.execute_reply":"2023-06-25T23:34:57.581128Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"        word    weight\n0    верблюд  0.282320\n1      дебил  3.756881\n2         бл  0.611891\n3      хохол  5.117917\n4        это -1.296658\n5   отдушина  0.156241\n6  затюканый  0.000000\n7  россиянин  0.626020\n8        мол  0.428603\n9        вон  0.692230\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Только плохие:","metadata":{}},{"cell_type":"code","source":"filtered_df = df[df['weight'] > 1]\nprint(filtered_df.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T23:35:06.561383Z","iopub.execute_input":"2023-06-25T23:35:06.561739Z","iopub.status.idle":"2023-06-25T23:35:06.571117Z","shell.execute_reply.started":"2023-06-25T23:35:06.561710Z","shell.execute_reply":"2023-06-25T23:35:06.570138Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"          word    weight\n1        дебил  3.756881\n3        хохол  5.117917\n10      хохлов  3.791348\n25      писать  1.479857\n27        твой  3.520533\n38      ватник  1.629258\n48       тупой  3.984838\n84       ебать  2.947675\n86       шизик  1.743394\n87  обсираться  1.511760\n","output_type":"stream"}]}]}