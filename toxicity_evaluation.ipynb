{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Model for style transfer accuracy"
      ],
      "metadata": {
        "id": "YHZhwNZUjsTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxPfB7HJbAkW",
        "outputId": "d8d646f5-1b54-4dba-c5ba-0cefc8f7585c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QCHyG-qc8Vq",
        "outputId": "92de8d10-65c0-44da-9fed-c81644656fb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1EJ6M_w3ci3o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Машинка/lemmatized.csv')"
      ],
      "metadata": {
        "id": "2Y9hezDbcjdk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['comment', 'toxic']]\n",
        "data['id'] = np.arange(len(data))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jh8czRtXdD2G",
        "outputId": "8b5e2725-7b7b-47f0-d77c-6e8c98f31fa0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  toxic  id\n",
              "0                                 дворник уничтожать      1   0\n",
              "1  старший неделя шипеть принимать подкидыш котор...      0   1\n",
              "2                                полностью согласный      0   2\n",
              "3                        нога вверх ничто изменяться      0   3\n",
              "4                              значить левый ребенок      0   4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da4ff86e-8b5e-4d0f-a139-77cbb9956765\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>дворник уничтожать</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>старший неделя шипеть принимать подкидыш котор...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>полностью согласный</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>нога вверх ничто изменяться</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>значить левый ребенок</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da4ff86e-8b5e-4d0f-a139-77cbb9956765')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da4ff86e-8b5e-4d0f-a139-77cbb9956765 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da4ff86e-8b5e-4d0f-a139-77cbb9956765');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pb94KCChc0Z",
        "outputId": "2797ffa3-5203-4690-f132-15dc69dc3874"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment    665\n",
              "toxic        0\n",
              "id           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "S6HC8zJWhqfe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we cannot train on full data, so we'll just take 30K toxic + 30K non-toxic from it (out of 160K)\n",
        "import copy\n",
        "data_full = copy.deepcopy(data)\n",
        "data_toxic = data_full.loc[data_full['toxic'] == 1]\n",
        "data_nontoxic = data_full.loc[data_full['toxic'] == 0].sample(n = len(data_toxic))\n",
        "data = pd.concat([data_toxic, data_nontoxic], ignore_index = True)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pts8Sw7uvFAj",
        "outputId": "6800badb-fd95-4a75-d69e-93c6cd25b540"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62806, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(data['comment'])\n",
        "labels = list(data['toxic'])"
      ],
      "metadata": {
        "id": "W5Up9XpOdKAV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "CY52Pk5Adah2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=32,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "0MEtrAamdfwO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")"
      ],
      "metadata": {
        "id": "p1V3d0Msic54"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
      ],
      "metadata": {
        "id": "b1yzk0e8fUGQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "ePi-ULLefYHx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "1YAbT8Vkffod"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbHopJ1Ifjdm",
        "outputId": "92a77d3e-1612-4d4f-d144-6cf8d54d4176"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "CLWRoOFtfqC0",
        "outputId": "ab06a3ff-2860-454f-832e-b737cdfa45ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e240529153b6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6oZz-wufv9M",
        "outputId": "8652ddcf-b680-4e5e-ace6-5d302a597bdd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        if batch is None:\n",
        "          print(i, 'huinia')\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    total_val_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            total_val_correct += torch.sum(predictions == labels).item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    val_accuracy = total_val_correct / len(val_dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Машинка/model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Машинка/tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFZF_V9Wf3Iu",
        "outputId": "46af06f7-7e3d-48b8-ce17-028f24f71448"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 0.1873\n",
            "Validation Loss: 0.1618\n",
            "Validation Accuracy: 0.9406\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.1065\n",
            "Validation Loss: 0.1767\n",
            "Validation Accuracy: 0.9377\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.0597\n",
            "Validation Loss: 0.2154\n",
            "Validation Accuracy: 0.9360\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0346\n",
            "Validation Loss: 0.2333\n",
            "Validation Accuracy: 0.9274\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0256\n",
            "Validation Loss: 0.3359\n",
            "Validation Accuracy: 0.9358\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0189\n",
            "Validation Loss: 0.3428\n",
            "Validation Accuracy: 0.9346\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0156\n",
            "Validation Loss: 0.3335\n",
            "Validation Accuracy: 0.9338\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0146\n",
            "Validation Loss: 0.4096\n",
            "Validation Accuracy: 0.9342\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0176\n",
            "Validation Loss: 0.3497\n",
            "Validation Accuracy: 0.9323\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0142\n",
            "Validation Loss: 0.3216\n",
            "Validation Accuracy: 0.9319\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Машинка/tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Машинка/tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Машинка/tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/Машинка/tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Style transfer accuracy"
      ],
      "metadata": {
        "id": "k47KOuMFjgw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "HkYi7iqymF7x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def STA(tokenizer, model, preds, true_labels):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "\n",
        "  tokenizer: BERT tokenizer\n",
        "\n",
        "  model: BERT model\n",
        "\n",
        "  preds: list of strings\n",
        "\n",
        "  --------------------------\n",
        "\n",
        "  Return:\n",
        "\n",
        "  accuracy, embeddings\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  inputs = tokenizer.batch_encode_plus(\n",
        "    preds,\n",
        "    add_special_tokens=True,\n",
        "    max_length=32,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "  input_ids = inputs[\"input_ids\"].to(device)\n",
        "  attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "  # store embeddings for cosine similarity later\n",
        "  embeddings = outputs[0]\n",
        "\n",
        "  true_labels_tensor = torch.from_numpy(true_labels).long().to(device)\n",
        "\n",
        "\n",
        "  accuracy = accuracy_score(true_labels_tensor.cpu(), predictions.cpu())\n",
        "\n",
        "  return accuracy, embeddings"
      ],
      "metadata": {
        "id": "8Arn351sjotC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate STA for our predictions:"
      ],
      "metadata": {
        "id": "nwLkCg8smkll"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_w7iuZAclMnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEU\n",
        "\n",
        "> The metric will show how close we stored the content"
      ],
      "metadata": {
        "id": "hRyZIARtmqBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "Er2fyQL8nvUs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(texts):\n",
        "  result = []\n",
        "  for text in texts:\n",
        "    tokenized = text.split()\n",
        "    result.append(tokenized)\n",
        "  return result"
      ],
      "metadata": {
        "id": "HJ5LUqTHsVlI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(true_texts, pred_texts):\n",
        "  true_list = tokenize(true_texts)\n",
        "  pred_list = tokenize(pred_texts)\n",
        "\n",
        "  bleu_scores = []\n",
        "  for i in range(len(true_list)):\n",
        "    reference = [true_list[i]]\n",
        "    candidate = pred_list[i]\n",
        "    bleu = sentence_bleu(reference, candidate)\n",
        "    bleu_scores.append(bleu)\n",
        "\n",
        "  avg_bleu = np.mean(bleu_scores)\n",
        "\n",
        "  return bleu_scores, avg_bleu"
      ],
      "metadata": {
        "id": "LXej0ToNox3R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we calculate BLEU scores:"
      ],
      "metadata": {
        "id": "w9whRYn9xUs7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hf5RRgBOxUJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine similarity\n",
        "\n",
        "Again for checking if we stored content:\n",
        "\n",
        "We already stored embeddings for predicted texts from BERT. Now we need to calculate them for our original data (we'll also take sample not full data)"
      ],
      "metadata": {
        "id": "TxzfgPdvwRx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "2cQj_6H3yyw5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddings(texts, model, tokenizer):\n",
        "  \"\"\"\n",
        "  texts: list of original texts\n",
        "  \"\"\"\n",
        "  device = model.device\n",
        "  tokens = tokenizer(texts, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
        "  input_ids = tokens[\"input_ids\"].to(device)\n",
        "  attention_mask = tokens[\"attention_mask\"].to(device)\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "      embeddings = outputs[0]\n",
        "  return embeddings\n"
      ],
      "metadata": {
        "id": "3ZECuowEwQCC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(true_embeddings, pred_embeddings):\n",
        "  cosine_similarities = []\n",
        "  for i in range(len(true_embeddings)):\n",
        "    true_emb = true_embeddings[i].unsqueeze(0).detach().cpu().numpy()\n",
        "    pred_emb = pred_embeddings[i].unsqueeze(0).detach().cpu().numpy()\n",
        "    cos_sim = cosine_similarity(true_emb, pred_emb)[0][0]\n",
        "    cosine_similarities.append(cos_sim)\n",
        "\n",
        "  avg_cossim = np.mean(cosine_similarities)\n",
        "  return cosine_similarities, avg_cossim"
      ],
      "metadata": {
        "id": "KtIZ9O2JyIqq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's calculate cosine similarities between our true and predicted sentences"
      ],
      "metadata": {
        "id": "nanT32jA1X_a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ag_DLRh1XPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating baseline metrics\n",
        "\n",
        "Baseline: just deleting toxic words from a sentence"
      ],
      "metadata": {
        "id": "r2LdwQL7DUyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_words = pd.read_csv('/content/drive/MyDrive/Машинка/toxic_words.csv')\n",
        "toxic_words = list(toxic_words['word'])"
      ],
      "metadata": {
        "id": "KzvilDnNEcvG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_comments = pd.read_csv('/content/drive/MyDrive/Машинка/test_comments.csv')\n",
        "test_comments = test_comments.dropna()\n",
        "test_comments.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pslWhBz5Hine",
        "outputId": "5f6b2344-0c74-42ea-9aee-4bdca8cd49ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0   index                                            comment  \\\n",
              "0        4865   27328  чмо воспитаный ходить жуйка жу т навешивать ше...   \n",
              "1       27216  149944  правда написать сделать вывод объективно подоб...   \n",
              "2       10110   56610                                    слово пиздануть   \n",
              "3        3924   21896                                  пиздабол поискать   \n",
              "4       26912  149268                                    затыкаться мочь   \n",
              "\n",
              "   toxic  \n",
              "0      1  \n",
              "1      1  \n",
              "2      1  \n",
              "3      1  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb33f2e1-7aa3-4e46-a7ad-3de2a4f94f7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4865</td>\n",
              "      <td>27328</td>\n",
              "      <td>чмо воспитаный ходить жуйка жу т навешивать ше...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27216</td>\n",
              "      <td>149944</td>\n",
              "      <td>правда написать сделать вывод объективно подоб...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10110</td>\n",
              "      <td>56610</td>\n",
              "      <td>слово пиздануть</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3924</td>\n",
              "      <td>21896</td>\n",
              "      <td>пиздабол поискать</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26912</td>\n",
              "      <td>149268</td>\n",
              "      <td>затыкаться мочь</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb33f2e1-7aa3-4e46-a7ad-3de2a4f94f7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb33f2e1-7aa3-4e46-a7ad-3de2a4f94f7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb33f2e1-7aa3-4e46-a7ad-3de2a4f94f7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = list(test_comments['comment'])"
      ],
      "metadata": {
        "id": "0082TiPtIwi5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_toxic_words(sentence, toxic_words):\n",
        "  \"\"\"\n",
        "  sentence: string\n",
        "\n",
        "  toxic_words: list\n",
        "\n",
        "  \"\"\"\n",
        "  sent_list = sentence.split()\n",
        "  result = []\n",
        "  for token in sent_list:\n",
        "    if token in toxic_words:\n",
        "      continue\n",
        "    result.append(token)\n",
        "\n",
        "  return ' '.join(result)\n"
      ],
      "metadata": {
        "id": "SPWGum2CEv4Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_predictions(texts, toxic_words):\n",
        "  \"\"\"\n",
        "  texts: list\n",
        "\n",
        "  toxic_words: list\n",
        "  \"\"\"\n",
        "  clean_texts = []\n",
        "  for text in texts:\n",
        "    clean_text = delete_toxic_words(text, toxic_words)\n",
        "    clean_texts.append(clean_text)\n",
        "  return clean_texts\n"
      ],
      "metadata": {
        "id": "vnPiwyP7D2LD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_test = baseline_predictions(test_texts, toxic_words)"
      ],
      "metadata": {
        "id": "Ph7jZzjEHGnx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating STA"
      ],
      "metadata": {
        "id": "aCn8639KJGvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/Машинка/tokenizer\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Машинка/model\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTTbtGI9Me0t",
        "outputId": "88ff436d-2b1a-4cdd-9c3d-f8f45eed5bd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_baseline, baseline_embeddings = STA(tokenizer, model, baseline_test, np.ones(len(baseline_test), dtype = np.int64))"
      ],
      "metadata": {
        "id": "4iymuzYAJGBT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfMWNq8DPwM3",
        "outputId": "908d7a50-6d93-452b-9d7c-66a88f808f05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40820410205102553"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate cosine similarity"
      ],
      "metadata": {
        "id": "V5E5nOF0QVmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_embeddings = embeddings(test_texts, model, tokenizer)"
      ],
      "metadata": {
        "id": "SSf7d0_3QU28"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_embeddings = pred_embeddings"
      ],
      "metadata": {
        "id": "r-3-D3PGRgqF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save true embeddings\n",
        "# import pickle\n",
        "# with open('/content/drive/MyDrive/Машинка/true_embeddings.pkl', 'wb') as f:\n",
        "  #  pickle.dump(true_embeddings, f)"
      ],
      "metadata": {
        "id": "LJcWW9i7SUwv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load true embeddings - this is done because we reload Colab\n",
        "with open('/content/drive/MyDrive/Машинка/true_embeddings.pkl', 'rb') as f:\n",
        "    true_embeddings = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "IKJkR-QlSlJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities, avg_cossim = cosine_sim(true_embeddings, baseline_embeddings)"
      ],
      "metadata": {
        "id": "aFoBFdaqRVqZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_cossim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xaxzFNCR0q2",
        "outputId": "9c811079-1472-40f1-c003-ba5c90545d77"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.13730684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate BLEU"
      ],
      "metadata": {
        "id": "RLUteRZeTF1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_scores_baseline, avg_blue_baseline = bleu_score(test_texts, baseline_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLC7TJfBTH8O",
        "outputId": "e100ac1f-80c5-46f3-d62e-af7f5e081320"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_blue_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olLxjro6TxV9",
        "outputId": "2f24c3e8-6016-4a3f-b919-574aeb96e4c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2556643356785611\n"
          ]
        }
      ]
    }
  ]
}